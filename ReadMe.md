# PDF Entity Detection Pipeline â€“ Stage 1 (YOLOv8)

This project implements a **PDF entity detection pipeline** using **YOLOv8**. It focuses on detecting and classifying entities in digital PDFs, such as:

- **Headers**  
- **Tables**  
- **Text**  
- **Figures**  
- **Equations**  
- **Charts**  
- **Footers**  

> âš ï¸ Stage 1 is focused on **detection only**. No content extraction is performed.  

---

## ğŸ¯ Objective

The primary objectives of Stage 1 are:

1. Accurately detect layout entities in PDFs.  
2. Generate **annotated PDFs**, **JSON results**, and **visual preview images**.  
3. Establish a foundation for **Stage 2**, aiming for near **100% detection accuracy**.

---

## ğŸ›  Technologies & Tools

| Component | Purpose |
|-----------|---------|
| **Python 3.9** | Main programming language. |
| **YOLOv8s (pre-trained)** | Lightweight object detection model for layout entity detection. |
| **PyMuPDF (fitz)** | Manipulating PDFs and drawing bounding boxes. |
| **PIL / Pillow** | Image processing (PDF to image conversion). |
| **Ultralytics YOLO library** | YOLOv8 model APIs for inference. |
| **JSON** | Structured storage of detection results. |
| **Conda** | Environment management for reproducibility. |

---

## ğŸ“ Project Structure

doclaynet-yolo/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ my_pdfs/ # Sample PDFs for testing
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ annotated_pdfs/ # PDFs with detected bounding boxes
â”‚ â”œâ”€â”€ predictions/ # Annotated images
â”‚ â””â”€â”€ json/ # Detection results in JSON format
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ infer.py # Main inference script
â”‚ â”œâ”€â”€ utils.py # Helper functions
â”‚ â””â”€â”€ gpu_check.py # Verify GPU/CPU setup
â”œâ”€â”€ weights/ # Pre-trained YOLOv8 model weights
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md


---

## âš™ï¸ Setup Instructions

1. **Clone the repository**

git clone https://github.com/yourusername/pdf_detector_yolo.git
cd pdf_detector_yolo
Create and activate the Conda environment



conda create -n pdf_detector_yolo python=3.10 -y
conda activate pdf_detector_yolo
pip install -r requirements.txt
Verify GPU/CPU availability


python scripts/gpu_check.py
ğŸš€ Usage
Place PDFs in the folder:



data/my_pdfs/
Run inference:



python -m scripts.infer
Check outputs:

outputs/annotated_pdfs/ â†’ Annotated PDFs

outputs/predictions/ â†’ Annotated images per PDF page

outputs/json/ â†’ JSON with detection results (labels, bounding boxes, confidence scores)

ğŸ“Œ Notes
Stage 1 uses YOLOv8s for fast prototyping.

Large datasets and model weights are not included due to size. Download DocLayNet manually if needed.

.gitignore excludes large datasets, model weights, and outputs. Only sample PDFs and scripts are committed.

ğŸ— Stage 2 Plan
Upgrade detection model to PP-YOLOE-S for improved accuracy.

Aim for 100% entity classification accuracy.

Optimize inference for GPU and improve annotated PDF outputs.

Potentially include post-processing to reduce false positives and overlaps.

ğŸ“œ References
YOLOv8 Documentation

DocLayNet Dataset

PyMuPDF Documentation


